FLAGPERF_PATH: "/data/home/zhengzy/FlagPerf/operation"
FLAGPERF_LOG_PATH: "result"
##nvidia,iluvatar,or other
VENDOR: "nvidia"
# VENDOR: "cambricon"
# VENDOR: "metax"
# VENDOR: "kunlunxin"
FLAGPERF_LOG_LEVEL: "info"
# HOSTS: ["192.168.1.2"]
NPROC_PER_NODE: 1
# SSH_PORT: "22"
# HOSTS_PORTS: ["2222"]
# MASTER_PORT: "29501"
# SHM_SIZE: "32G"
# only for iluvatar,dual process operation, modify device id,0 or 1
# DEVICE: 0
# for nvidia, using " -- gpus all"
# for metax, using " --device=/dev/dri --device=/dev/mxcd --group-add video"
# for kunlunxin, using "--device=/dev/xpu0 --device=/dev/xpu1 --device=/dev/xpu2 --device=/dev/xpu3 --device=/dev/xpu4 --device=/dev/xpu5 --device=/dev/xpu6 --device=/dev/xpu7 --device=/dev/xpuctrl"
# for cambricon, using " --device=/dev/cambricon_dev0:/dev/cambricon_dev0 --device=/dev/cambricon_dev1:/dev/cambricon_dev1 --device=/dev/cambricon_dev2:/dev/cambricon_dev2 --device=/dev/cambricon_dev3:/dev/cambricon_dev3  --device=/dev/cambricon_dev4:/dev/cambricon_dev4  --device=/dev/cambricon_dev5:/dev/cambricon_dev5  --device=/dev/cambricon_dev6:/dev/cambricon_dev6   --device=/dev/cambricon_dev7:/dev/cambricon_dev7  --device=/dev/cambricon_ctl "
# for iluvatar, using ""
# for xxx, using
ACCE_CONTAINER_OPT: " --gpus all"
PIP_SOURCE: "https://mirror.baidu.com/pypi/simple"
CLEAR_CACHES: True
# for nvidia, using "CUDA_VISIBLE_DEVICES"
# for metax, using "MACA_VISIBLE_DEVICES"
# for cambricon, using "MLU_VISIBLE_DEVICES"
# for xxx, using
ACCE_VISIBLE_DEVICE_ENV_NAME: "CUDA_VISIBLE_DEVICES"
# "operation:dataFormat:chip": "docker_images"
# now only support flaggems and nativepytorch
CASES: 
    "abs:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "add:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "addmm:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "all:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "amax:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "argmax:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "bitwise_and:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "bitwise_not:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "bitwise_or:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "bmm:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "cos:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "cross_entropy_loss:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "div:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "dropout:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "eq:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "exp:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "ge:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "gelu:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "group_norm:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "gt:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "isinf:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "isnan:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "layer_norm:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "le:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "linear:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "log_softmax:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "lt:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "max:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "mean:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "min:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "mm:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "mul:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "mv:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "native_dropout:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "native_group_norm:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "ne:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "neg:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "outer:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "pow:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "prod:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "reciprocal:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "relu:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "rsqrt:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "rsub:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "sigmoid:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "silu:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "sin:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "softmax:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "sub:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "sum:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "tanh:FP16:119.5:nativetorch:L20": "ngctorch2403"
    "triu:FP16:119.5:nativetorch:L20": "ngctorch2403"

#    "mm:FP16:flaggems:A100_40_SXM": "ngctorch2403"
#    "mm:FP16:nativetorch:A100_40_SXM": "ngctorch2403"
#    'exp:FP32:nativetorch:R300p" : "xpytorch029"
#    'exp:FP32:flaggems:R300p" : "xpytorch029"
#    "abs:FP32:nativetorch:BI150": "bi150-410"
#    "argmax:BF16:312:flaggems:MLU": "camtorch0830"
